Hi! I want to build an agent that will come up daily at 09:00 and send me to my email and post in LinkedIn acc the news digest about last week fraud fight news and updates.
I need your step by step help to do so.

1. What platform will be best for this task?
2. Provide clear step-by-step instruction to implement it.
3. Propose how to make this flow more sexy.

Thanks!

Why Serverless with AWS and not N8N or zapier?

https://newsapi.org/ API key 4d970a7daa9b4d7990c9c474d413e52f
LD ClientID: 77e0a1xr99gm5m pass: WPL_AP1.WVUC04nyAWsr8AJZ.lUUTgA==
Access token
AQXeDvA8vdtjURZe7fTyXCAO7p0mHV0cB2ci_slWoj0bm9GHh2qIDnIMAAg2ObtyBwQbktX8QPEDKtwH6ewixeXpu-yvpNdY-TN0y34VIeEqivNldRc77CTXX3grMMUcBwdEGvWfEUNz7CSNo1RNQp6g51pZZa-YucEOzZw_ZVsRtXFWm5eDe3RzvkEBrELoTkUONn8IGBp1BdBZ6IF-hpMF8cQqdvq-MfX3qMnPBDm1G2ENzV1gFU54BhihILzMCIf_oERGHZAYvgSyX-9R2Fco3DQikOpn69Na-sAAc5ilaE0N_pYkwskCb3CNZsNw8ffHFDDfmbCePO7Px12oGBvikFAvGQ

curl -H "Authorization: Bearer YOUR_ACCESS_TOKEN" https://api.linkedin.com/v2/userinfo

curl -k -H "Authorization: Bearer AQXeDvA8vdtjURZe7fTyXCAO7p0mHV0cB2ci_slWoj0bm9GHh2qIDnIMAAg2ObtyBwQbktX8QPEDKtwH6ewixeXpu-yvpNdY-TN0y34VIeEqivNldRc77CTXX3grMMUcBwdEGvWfEUNz7CSNo1RNQp6g51pZZa-YucEOzZw_ZVsRtXFWm5eDe3RzvkEBrELoTkUONn8IGBp1BdBZ6IF-hpMF8cQqdvq-MfX3qMnPBDm1G2ENzV1gFU54BhihILzMCIf_oERGHZAYvgSyX-9R2Fco3DQikOpn69Na-sAAc5ilaE0N_pYkwskCb3CNZsNw8ffHFDDfmbCePO7Px12oGBvikFAvGQ" https://api.linkedin.com/v2/userinfo



{"sub":"WDC_T6Apje","email_verified":true,"name":"Evgeniy Vinnik","locale":{"country":"US","language":"en"},"given_name":"Evgeniy","family_name":"Vinnik","email":"vinnikev@gmail.com","picture":"https://media.licdn.com/dms/image/v2/C4D03AQGN1FXLdZtSLA/profile-displayphoto-shrink_100_100/profile-displayphoto-shrink_100_100/0/1639993572965?e=1756339200&v=beta&t=B3fpcUdtjcKKcqQ65E7KLfQ1gKO7ATtCVC2cAfP0cf8"}     ✓

 
# Use this code snippet in your app.
# If you need more information about configurations
# or implementing the sample code, visit the AWS docs:
# https://aws.amazon.com/developer/language/python/

import boto3
from botocore.exceptions import ClientError


def get_secret():

    secret_name = "rod/FraudNewsAgent/ApiKeys"
    region_name = "eu-north-1"

    # Create a Secrets Manager client
    session = boto3.session.Session()
    client = session.client(
        service_name='secretsmanager',
        region_name=region_name
    )

    try:
        get_secret_value_response = client.get_secret_value(
            SecretId=secret_name
        )
    except ClientError as e:
        # For a list of exceptions thrown, see
        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html
        raise e

    secret = get_secret_value_response['SecretString']

    # Your code goes here.







The Froud Digest (Weekly) by Proactive-Fraud-Advisor
PRIVACY.md

Of course\! Let's get this done. Roll up your sleeves. We'll go through this piece by piece. Follow this guide, and you'll have your agent running. No shortcuts, we do this right, or the cat gets it.

Here is your step-by-step implementation plan.

-----

### **Phase 1: Setup the Foundation (AWS & Security)**

This is the bedrock of our project. We need to set up our cloud environment and make sure our secrets are handled properly from the very beginning.

#### **Step 1: Get Your API Keys**

Before we touch AWS, let's get the keys we need to operate.

  * **NewsAPI:** Go to [NewsAPI.org](https://newsapi.org), register for a free developer account, and save the API key you are given.
  * **LinkedIn:** This one is a bit more involved.
    1.  You need a LinkedIn Page that you are an admin of. You can create one from your profile under the "Work" dropdown if needed.
    2.  Go to the [LinkedIn Developer Platform](https://www.google.com/search?q=https://www.linkedin.com/developers/apps/new) and click "Create app".
    3.  Fill out the form (App name, link to your LinkedIn Page, etc.).
    4.  Go to the "Products" tab for your new app and request access to **"Share on LinkedIn"** and **"Sign In with LinkedIn"**.
    5.  Go to the "Auth" tab. Note down your **Client ID** and **Client Secret**.
    6.  You will also need an **Access Token**. For a server-side agent like ours, you'll generate a long-lived access token through the OAuth 2.0 flow. 
	The developer portal has tools to help you generate one for your own account for testing. For production, you'd build a small one-time-run app to get a refreshable token.

#### **Step 2: Store Your Keys in AWS Secrets Manager**

This is non-negotiable. We do not put secrets in code.

1.  In the AWS Console, navigate to **AWS Secrets Manager**.
2.  Click **"Store a new secret"**.
3.  Select **"Other type of secret"**.
4.  Under **"Secret key/value"**, add a key for each secret. For example:
      * `NEWS_API_KEY`: `your_key_from_newsapi`
      * `LINKEDIN_CLIENT_ID`: `your_linkedin_client_id`
      * `LINKEDIN_CLIENT_SECRET`: `your_linkedin_client_secret`
      * `LINKEDIN_ACCESS_TOKEN`: `your_generated_access_token`
      * `LINKEDIN_AUTHOR_URN`: `urn:li:person:your_linkedin_id` (You get this `person_id` via an API call to the `/userinfo` endpoint after authenticating).
5.  Click **Next**.
6.  Give the secret a name, like `prod/FraudNewsAgent/ApiKeys`. Remember this name.
7.  Follow the prompts to save the secret.

#### **Step 3: Verify Your Email in AWS SES**

To send emails, AWS needs to know you own the email address.

1.  Navigate to **Amazon Simple Email Service (SES)** in the AWS Console.
2.  In the left menu, click **"Verified identities"**.
3.  Click **"Create identity"**.
4.  Choose **"Email address"**, enter the email you want to send *from* and *to* (can be the same one), and click **Create identity**.
5.  You will receive a verification email from AWS. Click the link inside it to complete the verification.

-----

### **Phase 2: Write and Package the Code (The Brains)**

Now we write the Python script that does all the work.

#### **Step 1: Prepare Your Local Folder**

On your computer, create a folder for this project, for example, `fraud-news-agent`.

#### **Step 2: Write the Python Code**

Inside that folder, create a file named `lambda_function.py`. This code will fetch secrets, get news, format it, and send it.

```python
import json
import os
import requests
import boto3
from datetime import datetime, timedelta

# Name of the secret in AWS Secrets Manager
SECRET_NAME = "prod/FraudNewsAgent/ApiKeys" 
REGION_NAME = "us-east-1" # Or your preferred region

def get_secrets():
    """Retrieves secrets from AWS Secrets Manager."""
    session = boto3.session.Session()
    client = session.client(service_name='secretsmanager', region_name=REGION_NAME)
    
    try:
        get_secret_value_response = client.get_secret_value(SecretId=SECRET_NAME)
    except Exception as e:
        print(f"Unable to retrieve secrets: {e}")
        raise e

    # Decrypts the secret using the associated KMS key
    secret = get_secret_value_response['SecretString']
    return json.loads(secret)

def get_fraud_news(api_key):
    """Fetches fraud-related news from the last week."""
    one_week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
    # A more robust query
    query = '("payment fraud" OR "financial crime" OR "identity theft" OR "kyc" OR "aml") AND (update OR news OR trend)'
    
    url = (f'https://newsapi.org/v2/everything?'
           f'q={query}&'
           f'from={one_week_ago}&'
           f'sortBy=popularity&'
           f'language=en&'
           f'pageSize=5&' # Get 5 top articles
           f'apiKey={api_key}')
    
    response = requests.get(url)
    response.raise_for_status() # Raises an exception for bad status codes
    return response.json().get('articles', [])

def format_digest_for_email(articles):
    """Formats a professional HTML email digest."""
    if not articles:
        return "No significant fraud news found this week."

    html_body = """
    <html>
    <head></head>
    <body style="font-family: Arial, sans-serif;">
        <h2>Weekly Fraud & Security News Digest</h2>
        <p>Here are the top stories from the past week:</p>
    """
    for article in articles:
        title = article['title']
        url = article['url']
        source = article['source']['name']
        html_body += f'<p><strong><a href="{url}">{title}</a></strong><br><small>Source: {source}</small></p>'

    html_body += '<p><em>Automated digest by your friendly Givi-bot.</em></p></body></html>'
    return html_body

def format_digest_for_linkedin(articles):
    """Formats a concise, engaging LinkedIn post."""
    if not articles:
        return None
        
    # We'll post the top 2 articles to keep it short and sweet for social media
    top_two = articles[:2]
    post_text = "This week's top fraud & security updates:\n\n"
    for article in top_two:
        post_text += f"➡️ {article['title']}\n{article['url']}\n\n"

    post_text += "#FraudPrevention #CyberSecurity #Fintech #RiskManagement #SecurityNews"
    return post_text

def send_email(html_body, secrets):
    """Sends the digest using AWS SES."""
    ses_client = boto3.client('ses', region_name=REGION_NAME)
    try:
        ses_client.send_email(
            Source=secrets['SENDER_EMAIL'], # Add your verified email to secrets
            Destination={'ToAddresses': [secrets['RECIPIENT_EMAIL']]}, # And this one too
            Message={
                'Subject': {'Data': f"Your Weekly Fraud News Digest - {datetime.now().strftime('%Y-%m-%d')}"},
                'Body': {'Html': {'Data': html_body}}
            }
        )
        print("Email sent successfully!")
    except Exception as e:
        print(f"Error sending email: {e}")

def post_to_linkedin(post_text, secrets):
    """Posts the digest to LinkedIn."""
    if not post_text:
        print("No content to post to LinkedIn.")
        return

    headers = {
        'Authorization': f"Bearer {secrets['LINKEDIN_ACCESS_TOKEN']}",
        'Content-Type': 'application/json',
        'X-Restli-Protocol-Version': '2.0.0'
    }
    payload = {
        "author": secrets['LINKEDIN_AUTHOR_URN'],
        "lifecycleState": "PUBLISHED",
        "specificContent": {
            "com.linkedin.ugc.ShareContent": {
                "shareCommentary": {
                    "text": post_text
                },
                "shareMediaCategory": "NONE"
            }
        },
        "visibility": {
            "com.linkedin.ugc.MemberNetworkVisibility": "PUBLIC"
        }
    }
    
    response = requests.post("https://api.linkedin.com/v2/ugcPosts", headers=headers, json=payload)
    if 200 <= response.status_code < 300:
        print("Posted to LinkedIn successfully!")
    else:
        print(f"Error posting to LinkedIn: {response.status_code} - {response.text}")


def lambda_handler(event, context):
    """Main function for AWS Lambda."""
    print("Agent starting...")
    try:
        secrets = get_secrets()
        
        # Make sure you add these two keys to your secret in Secrets Manager!
        if 'SENDER_EMAIL' not in secrets or 'RECIPIENT_EMAIL' not in secrets:
             raise ValueError("SENDER_EMAIL and RECIPIENT_EMAIL must be in secrets")

        articles = get_fraud_news(secrets['NEWS_API_KEY'])
        
        # 1. Email Flow
        email_html = format_digest_for_email(articles)
        send_email(email_html, secrets)

        # 2. LinkedIn Flow
        linkedin_text = format_digest_for_linkedin(articles)
        post_to_linkedin(linkedin_text, secrets)

        print("Agent finished.")
        return {'statusCode': 200, 'body': json.dumps('Process completed!')}
    except Exception as e:
        print(f"An error occurred: {e}")
        # This ensures any error is logged clearly in CloudWatch
        raise e

```

#### **Step 3: Create the Deployment Package**

Our code uses the `requests` library, which we must include.

1.  Open a terminal or command prompt in your `fraud-news-agent` folder.
2.  Run this command to install the library into this folder:
    ```bash
    pip install requests -t .
    ```
3.  You should now see `lambda_function.py` alongside a `requests` folder and other related files.
4.  Select **all the files and folders** inside `fraud-news-agent` and compress them into a `.zip` file. Name it `deployment_package.zip`. **Do not zip the parent folder itself.**

-----

### **Phase 3: Deploy and Schedule (The Action)**

Now we put our code in the cloud and tell it when to run.

#### **Step 1: Create the Lambda Function**

1.  In the AWS Console, go to **Lambda** and click **"Create function"**.
2.  Choose **"Author from scratch"**.
3.  **Function Name:** `FraudNewsAgent`
4.  **Runtime:** **Python 3.12** (or the latest supported Python version).
5.  **Architecture:** `x86_64`
6.  Expand **"Change default execution role"**.
      * Select **"Create a new role with basic Lambda permissions"**.
7.  Click **"Create function"**.

#### **Step 2: Configure the Function**

1.  **Upload Code:** On the function page, in the **"Code source"** box, click **"Upload from"** and select **".zip file"**. Upload your `deployment_package.zip`.
2.  **Add Permissions:**
      * Go to the **"Configuration"** tab and click on **"Permissions"** in the left menu.
      * Click the **Role name**. This opens the IAM console.
      * On the IAM role page, click **"Add permissions"** -\> **"Attach policies"**.
      * Search for and attach these two AWS managed policies:
          * `SecretsManagerReadWrite`
          * `AmazonSESFullAccess`
      * (In a real production environment, we'd create custom, more restrictive policies, but this is perfect for our project).
3.  **Increase Timeout:**
      * Go back to your Lambda's **"Configuration"** tab -\> **"General configuration"**.
      * Click **Edit**. Set the **Timeout** to **30 seconds**. This gives our function enough time to call the APIs without rushing. Click **Save**.

#### **Step 3: Set the Schedule**

1.  In your Lambda function's visual editor, click **"Add trigger"**.
2.  Select **"EventBridge (CloudWatch Events)"** as the source.
3.  Choose **"Create a new rule"**.
4.  **Rule name:** `RunDailyAt0900`
5.  **Schedule expression:** To run at 09:00 AM UTC every day, use the cron expression: `cron(0 9 * * ? *)`.
      * *Remember: This is UTC time\! Adjust the `9` based on your timezone. For example, for Israel time (IDT, UTC+3) you'd use `cron(0 6 * * ? *)` to have it run at 9 AM local time.*
6.  Click **"Add"**.

-----

### **Phase 4: Test it\!**

1.  In your Lambda function page, go to the **"Test"** tab.
2.  Create a new test event. The default "hello world" event is fine; our code doesn't use the event input.
3.  Click the orange **"Test"** button.
4.  Look at the execution results. You should see "Process completed\!" if everything worked. Check your email and your LinkedIn page\! If you see an error, the logs below will tell you exactly what went wrong.

You did it\! You now have a fully automated, serverless agent. Let it run for a few days and watch it work. Once you are comfortable with this, we can talk about making it even more "sexy" with IaC and other advanced features.

Great job, my friend. The cat is purring.


----------------------

Hey! Bro, what a killer idea! Seriously, this is exactly the kind of project that gets you noticed. It's not just "I know automation," it's "I build intelligent systems to stay ahead of the curve." This is pure gold for your CV and for the interviews we're prepping for. Building this shows you can integrate APIs, handle data, schedule tasks, and even use a bit of AI. This is how we get you that 32,000 NIS salary.

Let's get this done. I'll walk you through it, step-by-step. Grab a coffee, open up your n8n canvas, and let's build this thing.

Think of our workflow like an assembly line:
Trigger (Every morning) -> Fetch News (From the web) -> Process & Summarize (Make it smart) -> Distribute (Email & LinkedIn).

Prerequisites (Stuff to get ready first)
n8n Instance: You have one running, either on your machine, a server, or n8n.cloud.
Email Credentials: You need SMTP credentials to send email. If you use Gmail, you can use an App Password. It's more secure. We'll add this to n8n's credential store.
LinkedIn Credentials: This is the trickiest part, but a great skill to have. You'll need to create a Developer App on LinkedIn to get API access.
Go to the LinkedIn Developer Portal.
Create a new app. You'll need to associate it with a LinkedIn Page you manage (you can create one for yourself, like a personal brand page).
Once the app is created, under the "Products" tab, request access to the Share on LinkedIn and Sign In with LinkedIn products.
Go to the "Auth" tab and get your Client ID and Client Secret. We will save this in n8n's credentials. Heads up: LinkedIn can take a day or two to approve product access, so do this first!
Okay, got all that? Let's build the workflow node by node.

Step 1: The Trigger - "Cron Job"
This is our alarm clock. It will start the workflow every day.

On your n8n canvas, add a new node. Search for and select Cron.
Mode: Every Day.
Hour: 9.
Minute: 0.
Timezone: Make sure to set this to Asia/Jerusalem. This is super important so it runs at 9 AM your time, not UTC.
That's it. This node will now fire off at 9 AM every single day.

Step 2: Get The News - "RSS Feed Reader"
We need a source for our news. Instead of complex web scraping, we'll use a Google News RSS feed. It's free, reliable, and gives us structured data.

Add a new node and connect it to the Cron node. Search for RSS Feed Read.

In the URL field, we'll put a specially crafted Google News URL. This one will search for news about fraud from the last week.

https://news.google.com/rss/search?q="fraud+fight"+OR+"anti-fraud"+OR+"financial+crime"+when:7d&hl=en-US&gl=US&ceid=US:en
q=... is our search query. I've added a few terms to get better results.
when:7d tells Google to only fetch news from the last 7 days. Perfect!
hl=en-US ensures we get news in English.
Execute this node to test it. You should see a list of news items with titles, links, and publication dates.

Step 3: The AI Magic - Summarize the News
Okay, here’s where we get fancy. We could just post a list of links, but that's what interns do. We're senior DevOps engineers. We're going to use AI to create a smart, readable digest.

Add a new node. Search for OpenAI (or Anthropic / Google Generative AI if you prefer). Let's use OpenAI for this example.

Authentication: You'll need an API key from OpenAI. Add it to your n8n credentials.

Resource: Chat.

Model: gpt-4o (or gpt-3.5-turbo if you want to save a few cents).

Prompt: This is the most important part. We need to tell the AI exactly what to do. In the "Messages" section, add a User message. Click on the little </> expression editor button and paste this in:

You are a financial crime and fraud prevention analyst. Your task is to create a concise and professional weekly news digest.

Based on the following news articles, please do the following:
1.  Write a brief, one-paragraph summary of the key trends this week.
2.  List the top 3-5 most important articles with a one-sentence summary for each.
3.  Format the output clearly.

Here are the articles:

{{ $json.items.map(item => `Title: ${item.title}\nLink: ${item.link}`).join('\n\n') }}
This prompt does three things:

Gives the AI a persona (fraud prevention analyst).
Tells it exactly what format we want (summary + top articles).
Uses an n8n expression ({{...}}) to dynamically insert the titles and links of the articles we got from the RSS feed.
Run this node. The output should be a beautifully formatted text digest.

Step 4: Prepare the Posts - "Set" Node
We need slightly different content for email (which can be long and have HTML) and for LinkedIn (which should be shorter and have hashtags). The Set node is perfect for creating these variables.

Add a Set node and connect it to the AI node.
We'll create two variables:
Add Value -> String.
Name: emailBody
Value: Use the expression editor to grab the AI's output. We'll also add a nice greeting.
HTML

Hi team,<br><br>
Here is your weekly digest on the latest in the fight against fraud.<br><br>
---<br><br>
{{ $json.choices[0].message.content.replace(/\n/g, '<br>') }}
<br><br>
Have a great week!
Note: The .replace(/\n/g, '<br>') converts the AI's line breaks into HTML line breaks for the email.
Add Value -> String.
Name: linkedinPost
Value: Again, use the AI's output, but add hashtags and a call to action.
This week in #FraudPrevention: a quick look at the latest news and updates shaping the industry.

{{ $json.choices[0].message.content }}

#AntiFraud #FinancialCrime #CyberSecurity #Fintech #DevOps #Automation
Now we have two perfectly formatted pieces of content ready to go.

Step 5: Distribute! - Email and LinkedIn Nodes
This is the final step. We'll send our digest out to the world.

Email Node:

Add a Send Email node and connect it to the Set node.
Credential: Select your SMTP/Gmail credentials.
To: Your email address.
Subject: Weekly Fraud Fight News Digest
HTML: Toggle this on. Drag the emailBody variable from the input panel on the left into the HTML field. It will look like this: {{ $json.emailBody }}.
LinkedIn Node:

Add a LinkedIn node and also connect it to the Set node (you can connect one node to multiple outputs).
Credential: Select your LinkedIn API credentials.
Resource: Share.
Operation: Create.
Author: Select the LinkedIn page you created.
Content: Drag the linkedinPost variable from the input panel into the Text field. It will be {{ $json.linkedinPost }}.
The Final Workflow
Your final workflow on the canvas should look something like this:

Cron -> RSS Feed Read -> OpenAI -> Set -> (branched to) -> [Send Email, LinkedIn]

Don't forget to SAVE and ACTIVATE the workflow!

Bro, that's it! You've just built a fully automated, AI-powered content syndication agent. Put "Built an automated news aggregation and social media distribution system using n8n, AI APIs, and RSS" on your CV. In an interview, you can talk about how you handled API credentials, engineered prompts for the AI, and managed a scheduled workflow (a CI/CD-like principle!).

This is a serious project. Get it running, let me know if you hit any snags. We'll debug it together. This is one more solid step toward that 32k+ NIS goal. Let's go!







As for Step 3: The AI Magic - Summarize the News i will use Google Generative AI, please adjust your recommendations


G
Givi, senior DevOps engineer, co-worker and friend
Custom Gem

Show thinking
Of course, bro! Solid choice. Google's Gemini models are beasts, and showing you can work with different LLM providers is a huge plus. It tells employers you're flexible and not locked into one ecosystem. We'll swap out OpenAI for Google Generative AI. The logic is exactly the same, we just need to use a different tool and point to a different place to get the result.

Let's adjust the plan. Steps 1 and 2 are still perfect. We'll replace Step 3 and tweak the expressions in Step 4.

Step 3 (Revised): The AI Magic with Google Gemini
Here we'll use Google's AI to process our news digest.

Add a new node and connect it to your RSS Feed Read node. Search for Google Generative AI.

Authentication: This is the first thing you'll need.

Go to Google AI Studio.
Create an API key.
Back in n8n, in the Google Generative AI node, click "Credential for Google Generative AI API" -> "Create New". Give it a name and paste your API key in.
Resource: Set this to Chat Model.

Model: Choose gemini-1.5-pro or gemini-1.5-flash. Pro is more powerful, Flash is faster and cheaper. For this task, gemini-1.5-flash is more than enough.

Prompt: The prompt itself can be the same, but we'll put it in the "Text" field of the chat message. In the Messages section, under Contents, add a new item. Set its role to User and in the Text field for that user, click the </> expression editor button and paste this in:

You are a financial crime and fraud prevention analyst. Your task is to create a concise and professional weekly news digest.

Based on the following news articles, please do the following:
1.  Write a brief, one-paragraph summary of the key trends this week.
2.  List the top 3-5 most important articles with a one-sentence summary for each.
3.  Format the output clearly for easy reading.

Here are the articles:

{{ $json.items.map(item => `Title: ${item.title}\nLink: ${item.link}`).join('\n\n') }}
This is the same logic as before: we give the AI a persona and feed it the list of articles from our RSS node ($json.items).

Execute this node to test it. You'll get a beautiful summary from Google's AI. The output structure is a bit different from OpenAI's, so we'll adjust for that in the next step.

Step 4 (Revised): Prepare the Posts - "Set" Node
This step is almost the same, but we need to change the expressions to get the text from the Google AI node's output.

Add a Set node and connect it to the Google Generative AI node.

We'll create the same two variables, but with updated expressions:

Add Value -> String.

Name: emailBody
Value: The path to Google's response is $json.candidates[0].content.parts[0].text. So the expression is:
HTML

Hi team,<br><br>
Here is your weekly digest on the latest in the fight against fraud, powered by Google AI.<br><br>
---<br><br>
{{ $('Google Generative AI').item.json.candidates[0].content.parts[0].text.replace(/\n/g, '<br>') }}
<br><br>
Have a great week!
Notice I'm specifically referencing the node $('Google Generative AI') to make sure it grabs the right data. The .replace() function still works the same way to make it HTML-friendly.
Add Value -> String.

Name: linkedinPost
Value: Same deal here, just with the LinkedIn formatting and hashtags.
This week in #FraudPrevention, powered by Google's AI: a quick look at the latest news and updates shaping the industry.

{{ $('Google Generative AI').item.json.candidates[0].content.parts[0].text }}

#AntiFraud #FinancialCrime #CyberSecurity #Gemini #GoogleAI #Automation
I even updated the hashtags for you. Good touch.
That's it! The rest of your workflow (Step 5, the Email and LinkedIn nodes) will now work perfectly with these revised variables from the Set node.

You've successfully swapped out a core component of your system. This is a real-world engineering task, my friend. It demonstrates adaptability. Keep this up, and that 32k NIS is getting closer every day. Let me know what's next.

